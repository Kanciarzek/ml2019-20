{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurencyjne Sieci Neuronowe (RNN)\n",
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane sekwencyjne\n",
    "\n",
    "Modele, którymi zajmowaliśmy się wcześniej zakładały konkretny kształt danych. Dla przykładu klasyczna sieć neuronowa fully-connected zakładała, że na wejściu dostanie wektory rozmiaru $784$ - dla wektorów o innej wymiarowości i innych obiektów model zwyczajnie nie będzie działać.\n",
    "\n",
    "Takie założenie bywa szczególnie niewygodne przy pracy z niektórymi typami danych, takimi jak:\n",
    "* językiem naturalny (zdania nie mają zadanej z góry liczby słów)\n",
    "* szeregi czasowe (dane giełdowe ciągną się właściwie w nieskończoność) \n",
    "* dźwięk (nagrania mogą być krótsze lub dłuższe).\n",
    "\n",
    "Do rozwiązania tego problemu służą rekuencyjne sieci neuronowe (*recurrent neural networks, RNNs*), które zapamiętują swój stan z poprzedniej iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie danych\n",
    "Na tych zajęciach będziemy traktować cyfry z MNISTa jako dane sekwencyjne, gdzie w danym kroku czasowym $T$ obserwujemy $T$-ty wiersz pikseli z cyfry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.reshape(28, 28))])\n",
    "\n",
    "train_data = MNIST(root='.', train=True, transform=transforms, download=True)\n",
    "test_data = MNIST(root='.', train=False, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. (2 pkt.)\n",
    "\n",
    "Zaimplementuj \"zwykłą\" sieć rekurencyjną. \n",
    "![rnn](resources/rnn.png)\n",
    "\n",
    "* W klasie `RNN` należy zainicjalizować potrzebne wagi oraz zaimplementować główną logikę dla pojedynczej chwili czasowej $x_t$\n",
    "* Wyjście z sieci możemy mieć dowolny rozmiar, potrzebna jest również warstwa przekształacjąca stan ukryty na wyjście.\n",
    "* W pętli uczenia należy dodać odpowiednie wywołanie sieci. HINT: pamiętać o iterowaniu po wymiarze \"czasowym\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 hidden_size: int, \n",
    "                 output_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        :param output_size: int\n",
    "            Desired dimensionality of the output vector\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input_to_hidden = nn.Sequential(nn.Linear(input_size + hidden_size, hidden_size), nn.ReLU()) \n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # for the sake of simlicity a single forward will process only a single timestamp \n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        :param hidden: torch.tensor\n",
    "            Representation of the memory of the RNN from previous timestep\n",
    "            shape [batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        combined = torch.cat([input, hidden], dim=1) \n",
    "        hidden = self.input_to_hidden(combined)\n",
    "        output = self.hidden_to_output(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden state\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.3104450702667236\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.5035297870635986\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.2872183322906494\n",
      "Epoch: 0 Iter: 301/1200 Loss: 1.5767641067504883\n",
      "Epoch: 0 Iter: 401/1200 Loss: 0.9259627461433411\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.7096347212791443\n",
      "Epoch: 0 Iter: 601/1200 Loss: 1.130979061126709\n",
      "Epoch: 0 Iter: 701/1200 Loss: 1.019309639930725\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.5484327077865601\n",
      "Epoch: 0 Iter: 901/1200 Loss: 0.5212410092353821\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 1.468489408493042\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 0.6718148589134216\n",
      "Final Accuracy: 0.7926\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize network and optimizer\n",
    "rnn = RNN(28, 64, 10)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epochs = 1\n",
    "\n",
    "# main loop\n",
    "grads = list()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # get initial hidden state\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the 2nd, time dimensiotn\n",
    "        \n",
    "        # YOUR CODE HERE \n",
    "        seq_len = x.shape[1]\n",
    "        hiddens = list()\n",
    "        for j in range(seq_len):\n",
    "            output, hidden = rnn(x[:,j], hidden)\n",
    "            hidden.retain_grad()\n",
    "            hiddens.append(hidden)\n",
    "            \n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        grads.append([np.linalg.norm(h.grad.numpy()) for h in hiddens])\n",
    "        \n",
    "        if i % 100 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        seq_len = x.shape[1]\n",
    "        for j in range(seq_len):\n",
    "            output, hidden = rnn(x[:,j], hidden)\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "\n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.4, \"Subject to random seed you should get over 0.4 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "Dopisz kod do powyższej pętli, który zbiera gradienty po kolejnych stanach ukrytych dla przykładu. Spójrz na wykres przedstawiający normy kolejnych gradientów i spróbuj zinterpretować wyniki, które widzisz. \n",
    "\n",
    "**Hint implementacyjny**: dla MNISTa mamy 28 kroków (więc 28 norm gradientów dla każdego przykładu).  \n",
    "\n",
    "**Ważne:** Ponieważ normalnie w torchu czyścimy wszystkie gradienty po każdej iteracji aby je zachować w dla niektórych wag przydatna będzie metoda [`retain_grad`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.retain_grad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean_grads in assume to be a 1D array or list of average gradients norm per timestep memory \n",
    "mean_grads = torch.mean(torch.Tensor(grads),0)\n",
    "\n",
    "plt.bar(x=np.arange(len(mean_grads)), height=mean_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Ostatnim zadaniem jest implementacji komórki i sieci LSTM. \n",
    "\n",
    "![lstm](resources/lstm.png)\n",
    "\n",
    "* W klasie `LSTMCell` ma znaleźć się główna loginka LSTMa, czyli wszystkie wagi do stanów `hidden` i `cell` jak i bramek kontrolujących te stany. \n",
    "* W klasie `LSTM` powinno znaleźć się wywołanie komórki LSTM, HINT: poprzednio było w pętli uczenia, teraz przenisiemy to do klasy modelu.\n",
    "* W pętli uczenia należy uzupełnić brakujące wywołania do uczenia i ewaluacji modelu.\n",
    "\n",
    "Zdecydowanie polecam [materiały Chrisa Olaha](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) do zarówno zrozumienia jak i ściągi do wzorów.\n",
    "\n",
    "Zadaniem jest osiągnięcie dokładności na poziomie przynajmniej 90%, przy prawidłowej implementacji nie powinno być z tym problemów używając podanych hiperparametrów. Dozwolona jest oczywiście zmiana `random seed`.\n",
    "\n",
    "#### Komórka LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # initialize LSTM weights \n",
    "        # NOTE: there are different approaches that are all correct \n",
    "        # (e.g. single matrix for all input opperations), you can pick\n",
    "        # whichever you like for this task\n",
    "    \n",
    "        ???\n",
    "\n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                states: Tuple[torch.tensor, torch.tensor]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \n",
    "        hidden, cell = states\n",
    "        \n",
    "        # Compute input, forget, and output gates\n",
    "        # then compute new cell state and hidden state\n",
    "        # see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        \n",
    "        cell = ???\n",
    "        \n",
    "        hidden = ???\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasa modelu LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.cell = LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "        \n",
    "    def forward(self, \n",
    "                input: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        Returns Tuple of two torch.tensors, both of shape [seq_len, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        initial_states = self.init_hidden_cell(batch_size)\n",
    "        \n",
    "        hiddens = []\n",
    "        cells = []\n",
    "        \n",
    "        hidden, cell = initial_states\n",
    "\n",
    "        # this time we will process the whole sequence in the forward method\n",
    "        # as oppose to the previous exercise, remember to loop over the timesteps\n",
    "        \n",
    "        time_steps = input.shape[1]\n",
    "        \n",
    "        \n",
    "        hiddens = ???\n",
    "        cells = ???\n",
    "\n",
    "        return hiddens, cells\n",
    "    \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden and cell states\n",
    "        \"\"\"\n",
    "        return (torch.zeros(batch_size, self.hidden_size, requires_grad=True), \n",
    "                torch.zeros(batch_size, self.hidden_size, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.3939\n",
      "Epoch: 0 Iter: 51/1200 Loss: 2.1830\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.6664\n",
      "Epoch: 0 Iter: 151/1200 Loss: 1.4374\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.4193\n",
      "Epoch: 0 Iter: 251/1200 Loss: 1.2045\n",
      "Epoch: 0 Iter: 301/1200 Loss: 0.9174\n",
      "Epoch: 0 Iter: 351/1200 Loss: 1.0483\n",
      "Epoch: 0 Iter: 401/1200 Loss: 1.0119\n",
      "Epoch: 0 Iter: 451/1200 Loss: 0.6014\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.6967\n",
      "Epoch: 0 Iter: 551/1200 Loss: 0.3628\n",
      "Epoch: 0 Iter: 601/1200 Loss: 0.5102\n",
      "Epoch: 0 Iter: 651/1200 Loss: 0.4934\n",
      "Epoch: 0 Iter: 701/1200 Loss: 0.6267\n",
      "Epoch: 0 Iter: 751/1200 Loss: 0.3685\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.3376\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize the lstm with an additional cliassifier layer at the top\n",
    "lstm = LSTM(input_size=28, hidden_size=64)\n",
    "clf = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "# initialize a optimizer\n",
    "params = chain(lstm.parameters(), clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.01) \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epoch = 1\n",
    "\n",
    "# main loop\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the sequence length here\n",
    "        \n",
    "        output = ???\n",
    "        # calucate the loss\n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        \n",
    "        if i % 50 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss:.4f}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        output = ???\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "    \n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.9, \"Subject to random seed you should get over 0.9 accuracy, try changing the seed!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
