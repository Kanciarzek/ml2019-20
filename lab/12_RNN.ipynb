{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurencyjne Sieci Neuronowe (RNN)\n",
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane sekwencyjne\n",
    "\n",
    "Modele, którymi zajmowaliśmy się wcześniej zakładały konkretny kształt danych. Dla przykładu klasyczna sieć neuronowa fully-connected zakładała, że na wejściu dostanie wektory rozmiaru $784$ - dla wektorów o innej wymiarowości i innych obiektów model zwyczajnie nie będzie działać.\n",
    "\n",
    "Takie założenie bywa szczególnie niewygodne przy pracy z niektórymi typami danych, takimi jak:\n",
    "* językiem naturalny (zdania nie mają zadanej z góry liczby słów)\n",
    "* szeregi czasowe (dane giełdowe ciągną się właściwie w nieskończoność) \n",
    "* dźwięk (nagrania mogą być krótsze lub dłuższe).\n",
    "\n",
    "Do rozwiązania tego problemu służą rekuencyjne sieci neuronowe (*recurrent neural networks, RNNs*), które zapamiętują swój stan z poprzedniej iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie danych\n",
    "Na tych zajęciach będziemy traktować cyfry z MNISTa jako dane sekwencyjne, gdzie w danym kroku czasowym $T$ obserwujemy $T$-ty wiersz pikseli z cyfry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.reshape(28, 28))])\n",
    "\n",
    "train_data = MNIST(root='.', train=True, transform=transforms, download=True)\n",
    "test_data = MNIST(root='.', train=False, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. (2 pkt.)\n",
    "\n",
    "Zaimplementuj \"zwykłą\" sieć rekurencyjną. \n",
    "![rnn](resources/rnn.png)\n",
    "\n",
    "* W klasie `RNN` należy zainicjalizować potrzebne wagi oraz zaimplementować główną logikę dla pojedynczej chwili czasowej $x_t$\n",
    "* Wyjście z sieci możemy mieć dowolny rozmiar, potrzebna jest również warstwa przekształacjąca stan ukryty na wyjście.\n",
    "* W pętli uczenia należy dodać odpowiednie wywołanie sieci. HINT: pamiętać o iterowaniu po wymiarze \"czasowym\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 hidden_size: int, \n",
    "                 output_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        :param output_size: int\n",
    "            Desired dimensionality of the output vector\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input_to_hidden = nn.Sequential(nn.Linear(input_size + hidden_size, hidden_size), nn.Tanh()) \n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # for the sake of simlicity a single forward will process only a single timestamp \n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        :param hidden: torch.tensor\n",
    "            Representation of the memory of the RNN from previous timestep\n",
    "            shape [batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        combined = torch.cat([input, hidden], dim=1) \n",
    "        hidden = self.input_to_hidden(combined)\n",
    "        output = self.hidden_to_output(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden state\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.2938475608825684\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.4249786138534546\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.3291609287261963\n",
      "Epoch: 0 Iter: 301/1200 Loss: 0.6997631192207336\n",
      "Epoch: 0 Iter: 401/1200 Loss: 1.0571328401565552\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.9069295525550842\n",
      "Epoch: 0 Iter: 601/1200 Loss: 1.2494300603866577\n",
      "Epoch: 0 Iter: 701/1200 Loss: 0.7354866862297058\n",
      "Epoch: 0 Iter: 801/1200 Loss: 1.6838549375534058\n",
      "Epoch: 0 Iter: 901/1200 Loss: 1.4060970544815063\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 1.2930032014846802\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 1.2889032363891602\n",
      "Final Accuracy: 0.4804\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(133)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize network and optimizer\n",
    "rnn = RNN(28, 64, 10)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epochs = 1\n",
    "\n",
    "# main loop\n",
    "grads = list()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # get initial hidden state\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the 2nd, time dimensiotn\n",
    "        \n",
    "        # YOUR CODE HERE \n",
    "        seq_len = x.shape[1]\n",
    "        hiddens = list()\n",
    "        for j in range(seq_len):\n",
    "            output, hidden = rnn(x[:,j], hidden)\n",
    "            hidden.retain_grad()\n",
    "            hiddens.append(hidden)\n",
    "            \n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        grads.append([np.linalg.norm(h.grad.numpy()) for h in hiddens])\n",
    "        \n",
    "        if i % 100 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        seq_len = x.shape[1]\n",
    "        for j in range(seq_len):\n",
    "            output, hidden = rnn(x[:,j], hidden)\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "\n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.4, \"Subject to random seed you should get over 0.4 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "Dopisz kod do powyższej pętli, który zbiera gradienty po kolejnych stanach ukrytych dla przykładu. Spójrz na wykres przedstawiający normy kolejnych gradientów i spróbuj zinterpretować wyniki, które widzisz. \n",
    "\n",
    "**Hint implementacyjny**: dla MNISTa mamy 28 kroków (więc 28 norm gradientów dla każdego przykładu).  \n",
    "\n",
    "**Ważne:** Ponieważ normalnie w torchu czyścimy wszystkie gradienty po każdej iteracji aby je zachować w dla niektórych wag przydatna będzie metoda [`retain_grad`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.retain_grad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean_grads in assume to be a 1D array or list of average gradients norm per timestep memory \n",
    "mean_grads = torch.mean(torch.Tensor(grads),0)\n",
    "\n",
    "plt.bar(x=np.arange(len(mean_grads)), height=mean_grads)\n",
    "#Mamy tu do czynienia z zanikającym gradientem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Ostatnim zadaniem jest implementacji komórki i sieci LSTM. \n",
    "\n",
    "![lstm](resources/lstm.png)\n",
    "\n",
    "* W klasie `LSTMCell` ma znaleźć się główna loginka LSTMa, czyli wszystkie wagi do stanów `hidden` i `cell` jak i bramek kontrolujących te stany. \n",
    "* W klasie `LSTM` powinno znaleźć się wywołanie komórki LSTM, HINT: poprzednio było w pętli uczenia, teraz przenisiemy to do klasy modelu.\n",
    "* W pętli uczenia należy uzupełnić brakujące wywołania do uczenia i ewaluacji modelu.\n",
    "\n",
    "Zdecydowanie polecam [materiały Chrisa Olaha](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) do zarówno zrozumienia jak i ściągi do wzorów.\n",
    "\n",
    "Zadaniem jest osiągnięcie dokładności na poziomie przynajmniej 90%, przy prawidłowej implementacji nie powinno być z tym problemów używając podanych hiperparametrów. Dozwolona jest oczywiście zmiana `random seed`.\n",
    "\n",
    "#### Komórka LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # initialize LSTM weights \n",
    "        # NOTE: there are different approaches that are all correct \n",
    "        # (e.g. single matrix for all input opperations), you can pick\n",
    "        # whichever you like for this task\n",
    "    \n",
    "        self.forget_layer = nn.Sequential(nn.Linear(input_size + hidden_size, 1), nn.Sigmoid())\n",
    "        self.input_gate_layer = nn.Sequential(nn.Linear(input_size + hidden_size, hidden_size), nn.Sigmoid())\n",
    "        self.input_gate_layer2 = nn.Sequential(nn.Linear(input_size + hidden_size, hidden_size), nn.Tanh())\n",
    "        self.output_gate_layer = nn.Sequential(nn.Linear(input_size + hidden_size, hidden_size), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                states: Tuple[torch.tensor, torch.tensor]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \n",
    "        hidden, cell = states\n",
    "        \n",
    "        # Compute input, forget, and output gates\n",
    "        # then compute new cell state and hidden state\n",
    "        # see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        \n",
    "        input_concat = torch.cat([input, hidden], 1)\n",
    "        cell = torch.mul(cell, self.forget_layer(input_concat)) + torch.mul(self.input_gate_layer(input_concat), self.input_gate_layer2(input_concat))\n",
    "        \n",
    "        hidden = torch.mul(self.output_gate_layer(input_concat), torch.tanh(cell)) \n",
    "        \n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasa modelu LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.cell = LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "        \n",
    "    def forward(self, \n",
    "                input: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        Returns Tuple of two torch.tensors, both of shape [seq_len, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        initial_states = self.init_hidden_cell(batch_size)\n",
    "        \n",
    "        hiddens = []\n",
    "        cells = []\n",
    "        \n",
    "        hidden, cell = initial_states\n",
    "\n",
    "        # this time we will process the whole sequence in the forward method\n",
    "        # as oppose to the previous exercise, remember to loop over the timesteps\n",
    "        \n",
    "        time_steps = input.shape[1]\n",
    "        \n",
    "        for i in range(time_steps):\n",
    "            hidden, cell = self.cell(input[:,i], (hidden, cell))\n",
    "            hiddens.append(hidden)\n",
    "            cells.append(cell)\n",
    "\n",
    "        return hiddens, cells\n",
    "    \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden and cell states\n",
    "        \"\"\"\n",
    "        return (torch.zeros(batch_size, self.hidden_size, requires_grad=True), \n",
    "                torch.zeros(batch_size, self.hidden_size, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.3023\n",
      "Epoch: 0 Iter: 51/1200 Loss: 1.3233\n",
      "Epoch: 0 Iter: 101/1200 Loss: 0.7665\n",
      "Epoch: 0 Iter: 151/1200 Loss: 0.7842\n",
      "Epoch: 0 Iter: 201/1200 Loss: 0.4763\n",
      "Epoch: 0 Iter: 251/1200 Loss: 0.2066\n",
      "Epoch: 0 Iter: 301/1200 Loss: 0.2076\n",
      "Epoch: 0 Iter: 351/1200 Loss: 0.1897\n",
      "Epoch: 0 Iter: 401/1200 Loss: 0.2351\n",
      "Epoch: 0 Iter: 451/1200 Loss: 0.4256\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.1070\n",
      "Epoch: 0 Iter: 551/1200 Loss: 0.3753\n",
      "Epoch: 0 Iter: 601/1200 Loss: 0.2920\n",
      "Epoch: 0 Iter: 651/1200 Loss: 0.1178\n",
      "Epoch: 0 Iter: 701/1200 Loss: 0.1125\n",
      "Epoch: 0 Iter: 751/1200 Loss: 0.1946\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.1337\n",
      "Epoch: 0 Iter: 851/1200 Loss: 0.0608\n",
      "Epoch: 0 Iter: 901/1200 Loss: 0.0975\n",
      "Epoch: 0 Iter: 951/1200 Loss: 0.1514\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 0.1926\n",
      "Epoch: 0 Iter: 1051/1200 Loss: 0.1555\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 0.0796\n",
      "Epoch: 0 Iter: 1151/1200 Loss: 0.0247\n",
      "Final Accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize the lstm with an additional cliassifier layer at the top\n",
    "lstm = LSTM(input_size=28, hidden_size=64)\n",
    "clf = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "# initialize a optimizer\n",
    "params = chain(lstm.parameters(), clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.01) \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epoch = 1\n",
    "\n",
    "# main loop\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the sequence length here\n",
    "        \n",
    "        output = clf(lstm(x)[1][-1])\n",
    "        # calucate the loss\n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        \n",
    "        if i % 50 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss:.4f}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        output = clf(lstm(x)[1][-1])\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "    \n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.9, \"Subject to random seed you should get over 0.9 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
